{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00d49483-57be-4a2e-9aa4-9a0a7fd4fd4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.18.0-cp312-cp312-win_amd64.whl.metadata (3.3 kB)\n",
      "Collecting tensorflow-intel==2.18.0 (from tensorflow)\n",
      "  Downloading tensorflow_intel-2.18.0-cp312-cp312-win_amd64.whl.metadata (4.9 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading flatbuffers-24.12.23-py2.py3-none-any.whl.metadata (876 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\shahroz\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\shahroz\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\shahroz\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\shahroz\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\shahroz\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading termcolor-2.5.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\shahroz\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\shahroz\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.14.1)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading grpcio-1.68.1-cp312-cp312-win_amd64.whl.metadata (4.0 kB)\n",
      "Collecting tensorboard<2.19,>=2.18 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting keras>=3.5.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading keras-3.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in c:\\users\\shahroz\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\shahroz\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.11.0)\n",
      "Collecting ml-dtypes<0.5.0,>=0.4.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading ml_dtypes-0.4.1-cp312-cp312-win_amd64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\shahroz\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow) (0.44.0)\n",
      "Requirement already satisfied: rich in c:\\users\\shahroz\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (13.7.1)\n",
      "Collecting namex (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n",
      "Collecting optree (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading optree-0.13.1-cp312-cp312-win_amd64.whl.metadata (48 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\shahroz\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\shahroz\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\shahroz\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\shahroz\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2024.12.14)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\shahroz\\anaconda3\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.4.1)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\shahroz\\anaconda3\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\shahroz\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\shahroz\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\shahroz\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\shahroz\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.1.0)\n",
      "Downloading tensorflow-2.18.0-cp312-cp312-win_amd64.whl (7.5 kB)\n",
      "Downloading tensorflow_intel-2.18.0-cp312-cp312-win_amd64.whl (390.3 MB)\n",
      "   ---------------------------------------- 0.0/390.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.3/390.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.5/390.3 MB 1.3 MB/s eta 0:05:02\n",
      "   ---------------------------------------- 0.8/390.3 MB 1.3 MB/s eta 0:05:02\n",
      "   ---------------------------------------- 1.3/390.3 MB 1.5 MB/s eta 0:04:21\n",
      "   ---------------------------------------- 1.6/390.3 MB 1.6 MB/s eta 0:04:06\n",
      "   ---------------------------------------- 2.4/390.3 MB 1.8 MB/s eta 0:03:32\n",
      "   ---------------------------------------- 2.9/390.3 MB 2.0 MB/s eta 0:03:15\n",
      "   ---------------------------------------- 3.4/390.3 MB 2.1 MB/s eta 0:03:03\n",
      "   ---------------------------------------- 3.9/390.3 MB 2.0 MB/s eta 0:03:10\n",
      "   ---------------------------------------- 4.5/390.3 MB 2.1 MB/s eta 0:03:04\n",
      "    --------------------------------------- 5.0/390.3 MB 2.1 MB/s eta 0:03:00\n",
      "    --------------------------------------- 5.8/390.3 MB 2.3 MB/s eta 0:02:50\n",
      "    --------------------------------------- 6.3/390.3 MB 2.3 MB/s eta 0:02:47\n",
      "    --------------------------------------- 6.8/390.3 MB 2.3 MB/s eta 0:02:45\n",
      "    --------------------------------------- 7.3/390.3 MB 2.4 MB/s eta 0:02:41\n",
      "    --------------------------------------- 7.6/390.3 MB 2.4 MB/s eta 0:02:41\n",
      "    --------------------------------------- 7.9/390.3 MB 2.2 MB/s eta 0:02:53\n",
      "    --------------------------------------- 7.9/390.3 MB 2.2 MB/s eta 0:02:53\n",
      "    --------------------------------------- 7.9/390.3 MB 2.2 MB/s eta 0:02:53\n",
      "    --------------------------------------- 7.9/390.3 MB 2.2 MB/s eta 0:02:53\n",
      "    --------------------------------------- 8.1/390.3 MB 1.9 MB/s eta 0:03:26\n",
      "    --------------------------------------- 8.9/390.3 MB 1.9 MB/s eta 0:03:20\n",
      "    --------------------------------------- 9.7/390.3 MB 2.0 MB/s eta 0:03:10\n",
      "   - -------------------------------------- 11.0/390.3 MB 2.2 MB/s eta 0:02:55\n",
      "   - -------------------------------------- 12.3/390.3 MB 2.4 MB/s eta 0:02:41\n",
      "   - -------------------------------------- 14.2/390.3 MB 2.6 MB/s eta 0:02:25\n",
      "   - -------------------------------------- 15.7/390.3 MB 2.8 MB/s eta 0:02:15\n",
      "   - -------------------------------------- 16.8/390.3 MB 2.9 MB/s eta 0:02:11\n",
      "   - -------------------------------------- 17.3/390.3 MB 2.8 MB/s eta 0:02:11\n",
      "   - -------------------------------------- 17.8/390.3 MB 2.8 MB/s eta 0:02:12\n",
      "   - -------------------------------------- 18.4/390.3 MB 2.8 MB/s eta 0:02:13\n",
      "   - -------------------------------------- 18.6/390.3 MB 2.8 MB/s eta 0:02:13\n",
      "   - -------------------------------------- 18.9/390.3 MB 2.7 MB/s eta 0:02:17\n",
      "   - -------------------------------------- 18.9/390.3 MB 2.7 MB/s eta 0:02:17\n",
      "   - -------------------------------------- 19.1/390.3 MB 2.7 MB/s eta 0:02:20\n",
      "   -- ------------------------------------- 19.7/390.3 MB 2.6 MB/s eta 0:02:23\n",
      "   -- ------------------------------------- 19.9/390.3 MB 2.6 MB/s eta 0:02:24\n",
      "   -- ------------------------------------- 20.4/390.3 MB 2.6 MB/s eta 0:02:24\n",
      "   -- ------------------------------------- 21.2/390.3 MB 2.6 MB/s eta 0:02:23\n",
      "   -- ------------------------------------- 22.3/390.3 MB 2.6 MB/s eta 0:02:20\n",
      "   -- ------------------------------------- 23.3/390.3 MB 2.7 MB/s eta 0:02:16\n",
      "   -- ------------------------------------- 24.6/390.3 MB 2.8 MB/s eta 0:02:12\n",
      "   -- ------------------------------------- 26.2/390.3 MB 2.9 MB/s eta 0:02:07\n",
      "   -- ------------------------------------- 28.3/390.3 MB 3.0 MB/s eta 0:01:59\n",
      "   --- ------------------------------------ 30.7/390.3 MB 3.2 MB/s eta 0:01:52\n",
      "   --- ------------------------------------ 33.0/390.3 MB 3.4 MB/s eta 0:01:47\n",
      "   --- ------------------------------------ 35.7/390.3 MB 3.6 MB/s eta 0:01:40\n",
      "   --- ------------------------------------ 36.7/390.3 MB 3.6 MB/s eta 0:01:39\n",
      "   --- ------------------------------------ 37.2/390.3 MB 3.6 MB/s eta 0:01:39\n",
      "   --- ------------------------------------ 37.2/390.3 MB 3.6 MB/s eta 0:01:39\n",
      "   --- ------------------------------------ 37.5/390.3 MB 3.5 MB/s eta 0:01:42\n",
      "   --- ------------------------------------ 37.5/390.3 MB 3.5 MB/s eta 0:01:42\n",
      "   --- ------------------------------------ 37.7/390.3 MB 3.3 MB/s eta 0:01:46\n",
      "   --- ------------------------------------ 38.0/390.3 MB 3.3 MB/s eta 0:01:47\n",
      "   --- ------------------------------------ 38.5/390.3 MB 3.3 MB/s eta 0:01:47\n",
      "   ---- ----------------------------------- 39.1/390.3 MB 3.3 MB/s eta 0:01:47\n",
      "   ---- ----------------------------------- 40.6/390.3 MB 3.3 MB/s eta 0:01:46\n",
      "   ---- ----------------------------------- 41.7/390.3 MB 3.3 MB/s eta 0:01:45\n",
      "   ---- ----------------------------------- 43.0/390.3 MB 3.4 MB/s eta 0:01:43\n",
      "   ---- ----------------------------------- 44.6/390.3 MB 3.5 MB/s eta 0:01:40\n",
      "   ---- ----------------------------------- 46.7/390.3 MB 3.6 MB/s eta 0:01:37\n",
      "   ----- ---------------------------------- 49.0/390.3 MB 3.7 MB/s eta 0:01:33\n",
      "   ----- ---------------------------------- 51.6/390.3 MB 3.8 MB/s eta 0:01:30\n",
      "   ----- ---------------------------------- 54.3/390.3 MB 3.9 MB/s eta 0:01:26\n",
      "   ----- ---------------------------------- 57.4/390.3 MB 4.1 MB/s eta 0:01:22\n",
      "   ------ --------------------------------- 60.3/390.3 MB 4.2 MB/s eta 0:01:19\n",
      "   ------ --------------------------------- 62.9/390.3 MB 4.3 MB/s eta 0:01:16\n",
      "   ------ --------------------------------- 65.8/390.3 MB 4.5 MB/s eta 0:01:13\n",
      "   ------ --------------------------------- 67.9/390.3 MB 4.5 MB/s eta 0:01:12\n",
      "   ------- -------------------------------- 68.9/390.3 MB 4.6 MB/s eta 0:01:11\n",
      "   ------- -------------------------------- 69.7/390.3 MB 4.5 MB/s eta 0:01:11\n",
      "   ------- -------------------------------- 70.5/390.3 MB 4.5 MB/s eta 0:01:11\n",
      "   ------- -------------------------------- 72.1/390.3 MB 4.6 MB/s eta 0:01:10\n",
      "   ------- -------------------------------- 73.7/390.3 MB 4.6 MB/s eta 0:01:09\n",
      "   ------- -------------------------------- 74.4/390.3 MB 4.6 MB/s eta 0:01:09\n",
      "   ------- -------------------------------- 74.7/390.3 MB 4.6 MB/s eta 0:01:10\n",
      "   ------- -------------------------------- 74.7/390.3 MB 4.6 MB/s eta 0:01:10\n",
      "   ------- -------------------------------- 75.0/390.3 MB 4.5 MB/s eta 0:01:11\n",
      "   ------- -------------------------------- 75.0/390.3 MB 4.5 MB/s eta 0:01:11\n",
      "   ------- -------------------------------- 75.0/390.3 MB 4.5 MB/s eta 0:01:11\n",
      "   ------- -------------------------------- 75.0/390.3 MB 4.5 MB/s eta 0:01:11\n",
      "   ------- -------------------------------- 75.0/390.3 MB 4.5 MB/s eta 0:01:11\n",
      "   ------- -------------------------------- 75.2/390.3 MB 4.2 MB/s eta 0:01:15\n",
      "   ------- -------------------------------- 75.8/390.3 MB 4.2 MB/s eta 0:01:16\n",
      "   ------- -------------------------------- 76.8/390.3 MB 4.2 MB/s eta 0:01:15\n",
      "   -------- ------------------------------- 78.6/390.3 MB 4.2 MB/s eta 0:01:15\n",
      "   -------- ------------------------------- 79.4/390.3 MB 4.2 MB/s eta 0:01:14\n",
      "   -------- ------------------------------- 80.7/390.3 MB 4.2 MB/s eta 0:01:14\n",
      "   -------- ------------------------------- 82.1/390.3 MB 4.2 MB/s eta 0:01:13\n",
      "   -------- ------------------------------- 83.9/390.3 MB 4.3 MB/s eta 0:01:12\n",
      "   -------- ------------------------------- 85.7/390.3 MB 4.3 MB/s eta 0:01:11\n",
      "   --------- ------------------------------ 88.1/390.3 MB 4.4 MB/s eta 0:01:09\n",
      "   --------- ------------------------------ 89.9/390.3 MB 4.4 MB/s eta 0:01:08\n",
      "   --------- ------------------------------ 92.5/390.3 MB 4.5 MB/s eta 0:01:06\n",
      "   --------- ------------------------------ 95.2/390.3 MB 4.6 MB/s eta 0:01:05\n",
      "   --------- ------------------------------ 97.5/390.3 MB 4.7 MB/s eta 0:01:03\n",
      "   ---------- ----------------------------- 100.1/390.3 MB 4.7 MB/s eta 0:01:02\n",
      "   ---------- ----------------------------- 102.5/390.3 MB 4.8 MB/s eta 0:01:00\n",
      "   ---------- ----------------------------- 104.1/390.3 MB 4.8 MB/s eta 0:01:00\n",
      "   ---------- ----------------------------- 104.9/390.3 MB 4.8 MB/s eta 0:01:00\n",
      "   ---------- ----------------------------- 105.4/390.3 MB 4.8 MB/s eta 0:01:00\n",
      "   ---------- ----------------------------- 106.2/390.3 MB 4.8 MB/s eta 0:01:00\n",
      "   ---------- ----------------------------- 106.4/390.3 MB 4.8 MB/s eta 0:01:00\n",
      "   ---------- ----------------------------- 106.7/390.3 MB 4.7 MB/s eta 0:01:01\n",
      "   ---------- ----------------------------- 106.7/390.3 MB 4.7 MB/s eta 0:01:01\n",
      "   ---------- ----------------------------- 107.0/390.3 MB 4.7 MB/s eta 0:01:01\n",
      "   ---------- ----------------------------- 107.2/390.3 MB 4.6 MB/s eta 0:01:02\n",
      "   ---------- ----------------------------- 107.2/390.3 MB 4.6 MB/s eta 0:01:02\n",
      "   ---------- ----------------------------- 107.2/390.3 MB 4.6 MB/s eta 0:01:02\n",
      "   ----------- ---------------------------- 107.5/390.3 MB 4.5 MB/s eta 0:01:03\n",
      "   ----------- ---------------------------- 107.7/390.3 MB 4.5 MB/s eta 0:01:04\n",
      "   ----------- ---------------------------- 108.0/390.3 MB 4.4 MB/s eta 0:01:04\n",
      "   ----------- ---------------------------- 108.3/390.3 MB 4.4 MB/s eta 0:01:05\n",
      "   ----------- ---------------------------- 108.5/390.3 MB 4.4 MB/s eta 0:01:05\n",
      "   ----------- ---------------------------- 108.5/390.3 MB 4.4 MB/s eta 0:01:05\n",
      "   ----------- ---------------------------- 108.8/390.3 MB 4.3 MB/s eta 0:01:06\n",
      "   ----------- ---------------------------- 108.8/390.3 MB 4.3 MB/s eta 0:01:06\n",
      "   ----------- ---------------------------- 108.8/390.3 MB 4.3 MB/s eta 0:01:06\n",
      "   ----------- ---------------------------- 108.8/390.3 MB 4.3 MB/s eta 0:01:06\n",
      "   ----------- ---------------------------- 108.8/390.3 MB 4.3 MB/s eta 0:01:06\n",
      "   ----------- ---------------------------- 109.1/390.3 MB 4.1 MB/s eta 0:01:08\n",
      "   ----------- ---------------------------- 109.6/390.3 MB 4.1 MB/s eta 0:01:09\n",
      "   ----------- ---------------------------- 109.8/390.3 MB 4.1 MB/s eta 0:01:09\n",
      "   ----------- ---------------------------- 110.4/390.3 MB 4.1 MB/s eta 0:01:09\n",
      "   ----------- ---------------------------- 110.9/390.3 MB 4.1 MB/s eta 0:01:09\n",
      "   ----------- ---------------------------- 111.7/390.3 MB 4.1 MB/s eta 0:01:09\n",
      "   ----------- ---------------------------- 112.2/390.3 MB 4.0 MB/s eta 0:01:09\n",
      "   ----------- ---------------------------- 112.5/390.3 MB 4.0 MB/s eta 0:01:10\n",
      "   ----------- ---------------------------- 112.7/390.3 MB 4.0 MB/s eta 0:01:10\n",
      "   ----------- ---------------------------- 113.2/390.3 MB 4.0 MB/s eta 0:01:10\n",
      "   ----------- ---------------------------- 113.8/390.3 MB 4.0 MB/s eta 0:01:10\n",
      "   ----------- ---------------------------- 114.3/390.3 MB 4.0 MB/s eta 0:01:10\n",
      "   ----------- ---------------------------- 115.1/390.3 MB 4.0 MB/s eta 0:01:10\n",
      "   ----------- ---------------------------- 115.9/390.3 MB 4.0 MB/s eta 0:01:10\n",
      "   ----------- ---------------------------- 116.4/390.3 MB 3.9 MB/s eta 0:01:10\n",
      "   ----------- ---------------------------- 116.7/390.3 MB 3.9 MB/s eta 0:01:10\n",
      "   ----------- ---------------------------- 116.7/390.3 MB 3.9 MB/s eta 0:01:10\n",
      "   ----------- ---------------------------- 116.9/390.3 MB 3.9 MB/s eta 0:01:11\n",
      "   ------------ --------------------------- 117.4/390.3 MB 3.9 MB/s eta 0:01:10\n",
      "   ------------ --------------------------- 118.0/390.3 MB 3.9 MB/s eta 0:01:10\n",
      "   ------------ --------------------------- 118.2/390.3 MB 3.9 MB/s eta 0:01:10\n",
      "   ------------ --------------------------- 118.5/390.3 MB 3.9 MB/s eta 0:01:10\n",
      "   ------------ --------------------------- 118.8/390.3 MB 3.9 MB/s eta 0:01:10\n",
      "   ------------ --------------------------- 119.0/390.3 MB 3.9 MB/s eta 0:01:10\n",
      "   ------------ --------------------------- 119.3/390.3 MB 3.9 MB/s eta 0:01:11\n",
      "   ------------ --------------------------- 119.5/390.3 MB 3.9 MB/s eta 0:01:11\n",
      "   ------------ --------------------------- 119.5/390.3 MB 3.9 MB/s eta 0:01:11\n",
      "   ------------ --------------------------- 119.8/390.3 MB 3.8 MB/s eta 0:01:11\n",
      "   ------------ --------------------------- 119.8/390.3 MB 3.8 MB/s eta 0:01:11\n",
      "   ------------ --------------------------- 119.8/390.3 MB 3.8 MB/s eta 0:01:11\n",
      "   ------------ --------------------------- 119.8/390.3 MB 3.8 MB/s eta 0:01:11\n",
      "   ------------ --------------------------- 119.8/390.3 MB 3.8 MB/s eta 0:01:11\n",
      "   ------------ --------------------------- 119.8/390.3 MB 3.8 MB/s eta 0:01:11\n",
      "   ------------ --------------------------- 120.1/390.3 MB 3.8 MB/s eta 0:01:11\n",
      "   ------------ --------------------------- 120.1/390.3 MB 3.8 MB/s eta 0:01:11\n",
      "   ------------ --------------------------- 120.3/390.3 MB 3.8 MB/s eta 0:01:12\n",
      "   ------------ --------------------------- 120.6/390.3 MB 3.8 MB/s eta 0:01:12\n",
      "   ------------ --------------------------- 120.8/390.3 MB 3.8 MB/s eta 0:01:12\n",
      "   ------------ --------------------------- 121.1/390.3 MB 3.8 MB/s eta 0:01:12\n",
      "   ------------ --------------------------- 121.4/390.3 MB 3.7 MB/s eta 0:01:12\n",
      "   ------------ --------------------------- 121.6/390.3 MB 3.7 MB/s eta 0:01:13\n",
      "   ------------ --------------------------- 122.2/390.3 MB 3.7 MB/s eta 0:01:14\n",
      "   ------------ --------------------------- 122.4/390.3 MB 3.6 MB/s eta 0:01:15\n",
      "   ------------ --------------------------- 122.7/390.3 MB 3.6 MB/s eta 0:01:15\n",
      "   ------------ --------------------------- 122.9/390.3 MB 3.6 MB/s eta 0:01:16\n",
      "   ------------ --------------------------- 123.5/390.3 MB 3.5 MB/s eta 0:01:16\n",
      "   ------------ --------------------------- 123.7/390.3 MB 3.5 MB/s eta 0:01:16\n",
      "   ------------ --------------------------- 124.0/390.3 MB 3.5 MB/s eta 0:01:16\n",
      "   ------------ --------------------------- 124.3/390.3 MB 3.5 MB/s eta 0:01:16\n",
      "   ------------ --------------------------- 124.5/390.3 MB 3.5 MB/s eta 0:01:16\n",
      "   ------------ --------------------------- 124.8/390.3 MB 3.5 MB/s eta 0:01:16\n",
      "   ------------ --------------------------- 125.0/390.3 MB 3.5 MB/s eta 0:01:16\n",
      "   ------------ --------------------------- 125.3/390.3 MB 3.5 MB/s eta 0:01:16\n",
      "   ------------ --------------------------- 125.6/390.3 MB 3.5 MB/s eta 0:01:16\n",
      "   ------------ --------------------------- 125.8/390.3 MB 3.5 MB/s eta 0:01:16\n",
      "   ------------ --------------------------- 125.8/390.3 MB 3.5 MB/s eta 0:01:16\n",
      "   ------------ --------------------------- 125.8/390.3 MB 3.5 MB/s eta 0:01:16\n",
      "   ------------ --------------------------- 126.1/390.3 MB 3.4 MB/s eta 0:01:18\n",
      "   ------------ --------------------------- 126.1/390.3 MB 3.4 MB/s eta 0:01:18\n",
      "   ------------ --------------------------- 126.1/390.3 MB 3.4 MB/s eta 0:01:18\n",
      "   ------------ --------------------------- 126.1/390.3 MB 3.4 MB/s eta 0:01:18\n",
      "   ------------ --------------------------- 126.1/390.3 MB 3.4 MB/s eta 0:01:18\n",
      "   ------------ --------------------------- 126.4/390.3 MB 3.1 MB/s eta 0:01:25\n",
      "   ------------ --------------------------- 126.6/390.3 MB 3.1 MB/s eta 0:01:25\n",
      "   ------------- -------------------------- 127.4/390.3 MB 3.0 MB/s eta 0:01:27\n",
      "   ------------- -------------------------- 127.9/390.3 MB 3.0 MB/s eta 0:01:27\n",
      "   ------------- -------------------------- 129.0/390.3 MB 3.1 MB/s eta 0:01:26\n",
      "   ------------- -------------------------- 130.0/390.3 MB 3.1 MB/s eta 0:01:25\n",
      "   ------------- -------------------------- 131.6/390.3 MB 3.2 MB/s eta 0:01:22\n",
      "   ------------- -------------------------- 132.4/390.3 MB 3.2 MB/s eta 0:01:22\n",
      "   ------------- -------------------------- 133.4/390.3 MB 3.2 MB/s eta 0:01:21\n",
      "   ------------- -------------------------- 135.0/390.3 MB 3.2 MB/s eta 0:01:20\n",
      "   ------------- -------------------------- 136.1/390.3 MB 3.2 MB/s eta 0:01:19\n",
      "   -------------- ------------------------- 137.6/390.3 MB 3.3 MB/s eta 0:01:18\n",
      "   -------------- ------------------------- 139.5/390.3 MB 3.3 MB/s eta 0:01:17\n",
      "   -------------- ------------------------- 141.3/390.3 MB 3.3 MB/s eta 0:01:16\n",
      "   -------------- ------------------------- 143.4/390.3 MB 3.3 MB/s eta 0:01:15\n",
      "   -------------- ------------------------- 146.0/390.3 MB 3.4 MB/s eta 0:01:13\n",
      "   --------------- ------------------------ 148.6/390.3 MB 3.4 MB/s eta 0:01:12\n",
      "   --------------- ------------------------ 152.0/390.3 MB 3.4 MB/s eta 0:01:11\n",
      "   --------------- ------------------------ 153.9/390.3 MB 3.4 MB/s eta 0:01:11\n",
      "   --------------- ------------------------ 155.2/390.3 MB 3.3 MB/s eta 0:01:11\n",
      "   --------------- ------------------------ 156.0/390.3 MB 3.3 MB/s eta 0:01:12\n",
      "   ---------------- ----------------------- 157.0/390.3 MB 3.2 MB/s eta 0:01:13\n",
      "   ---------------- ----------------------- 158.3/390.3 MB 3.2 MB/s eta 0:01:13\n",
      "   ---------------- ----------------------- 159.6/390.3 MB 3.1 MB/s eta 0:01:14\n",
      "   ---------------- ----------------------- 161.0/390.3 MB 3.1 MB/s eta 0:01:14\n",
      "   ---------------- ----------------------- 162.8/390.3 MB 3.1 MB/s eta 0:01:13\n",
      "   ---------------- ----------------------- 164.6/390.3 MB 3.2 MB/s eta 0:01:12\n",
      "   ----------------- ---------------------- 166.7/390.3 MB 3.2 MB/s eta 0:01:10\n",
      "   ----------------- ---------------------- 169.1/390.3 MB 3.3 MB/s eta 0:01:09\n",
      "   ----------------- ---------------------- 171.7/390.3 MB 3.3 MB/s eta 0:01:07\n",
      "   ----------------- ---------------------- 174.3/390.3 MB 3.3 MB/s eta 0:01:05\n",
      "   ------------------ --------------------- 176.7/390.3 MB 3.4 MB/s eta 0:01:03\n",
      "   ------------------ --------------------- 178.8/390.3 MB 3.5 MB/s eta 0:01:01\n",
      "   ------------------ --------------------- 181.1/390.3 MB 3.7 MB/s eta 0:00:58\n",
      "   ------------------ --------------------- 183.2/390.3 MB 3.7 MB/s eta 0:00:56\n",
      "   ------------------- -------------------- 185.6/390.3 MB 3.8 MB/s eta 0:00:55\n",
      "   ------------------- -------------------- 188.7/390.3 MB 3.8 MB/s eta 0:00:53\n",
      "   ------------------- -------------------- 190.6/390.3 MB 3.9 MB/s eta 0:00:52\n",
      "   ------------------- -------------------- 191.9/390.3 MB 3.9 MB/s eta 0:00:51\n",
      "   ------------------- -------------------- 193.2/390.3 MB 3.9 MB/s eta 0:00:51\n",
      "   ------------------- -------------------- 194.0/390.3 MB 3.9 MB/s eta 0:00:51\n",
      "   ------------------- -------------------- 194.8/390.3 MB 3.9 MB/s eta 0:00:51\n",
      "   -------------------- ------------------- 195.6/390.3 MB 3.9 MB/s eta 0:00:51\n",
      "   -------------------- ------------------- 196.9/390.3 MB 3.9 MB/s eta 0:00:50\n",
      "   -------------------- ------------------- 197.9/390.3 MB 3.9 MB/s eta 0:00:50\n",
      "   -------------------- ------------------- 198.2/390.3 MB 3.9 MB/s eta 0:00:50\n",
      "   -------------------- ------------------- 198.2/390.3 MB 3.9 MB/s eta 0:00:50\n",
      "   -------------------- ------------------- 198.2/390.3 MB 3.9 MB/s eta 0:00:50\n",
      "   -------------------- ------------------- 198.2/390.3 MB 3.9 MB/s eta 0:00:50\n",
      "   -------------------- ------------------- 198.4/390.3 MB 3.6 MB/s eta 0:00:54\n",
      "   -------------------- ------------------- 198.7/390.3 MB 3.6 MB/s eta 0:00:54\n",
      "   -------------------- ------------------- 199.8/390.3 MB 3.5 MB/s eta 0:00:55\n",
      "   -------------------- ------------------- 200.8/390.3 MB 3.5 MB/s eta 0:00:55\n",
      "   -------------------- ------------------- 202.1/390.3 MB 3.4 MB/s eta 0:00:55\n",
      "   -------------------- ------------------- 203.9/390.3 MB 3.4 MB/s eta 0:00:55\n",
      "   --------------------- ------------------ 205.8/390.3 MB 3.4 MB/s eta 0:00:55\n",
      "   --------------------- ------------------ 207.9/390.3 MB 3.4 MB/s eta 0:00:53\n",
      "   --------------------- ------------------ 210.2/390.3 MB 3.5 MB/s eta 0:00:52\n",
      "   --------------------- ------------------ 211.8/390.3 MB 3.5 MB/s eta 0:00:51\n",
      "   --------------------- ------------------ 213.9/390.3 MB 3.6 MB/s eta 0:00:50\n",
      "   ---------------------- ----------------- 216.5/390.3 MB 3.7 MB/s eta 0:00:48\n",
      "   ---------------------- ----------------- 218.4/390.3 MB 3.7 MB/s eta 0:00:46\n",
      "   ---------------------- ----------------- 220.7/390.3 MB 3.8 MB/s eta 0:00:45\n",
      "   ---------------------- ----------------- 223.1/390.3 MB 3.9 MB/s eta 0:00:44\n",
      "   ----------------------- ---------------- 225.7/390.3 MB 4.0 MB/s eta 0:00:42\n",
      "   ----------------------- ---------------- 228.1/390.3 MB 4.1 MB/s eta 0:00:41\n",
      "   ----------------------- ---------------- 230.2/390.3 MB 4.1 MB/s eta 0:00:40\n",
      "   ----------------------- ---------------- 231.5/390.3 MB 4.1 MB/s eta 0:00:39\n",
      "   ----------------------- ---------------- 232.5/390.3 MB 4.2 MB/s eta 0:00:38\n",
      "   ----------------------- ---------------- 232.8/390.3 MB 4.2 MB/s eta 0:00:38\n",
      "   ----------------------- ---------------- 232.8/390.3 MB 4.2 MB/s eta 0:00:38\n",
      "   ----------------------- ---------------- 232.8/390.3 MB 4.2 MB/s eta 0:00:38\n",
      "   ----------------------- ---------------- 232.8/390.3 MB 4.2 MB/s eta 0:00:38\n",
      "   ----------------------- ---------------- 233.0/390.3 MB 4.1 MB/s eta 0:00:38\n",
      "   ----------------------- ---------------- 233.8/390.3 MB 4.3 MB/s eta 0:00:37\n",
      "   ------------------------ --------------- 235.1/390.3 MB 4.3 MB/s eta 0:00:37\n",
      "   ------------------------ --------------- 236.7/390.3 MB 4.3 MB/s eta 0:00:36\n",
      "   ------------------------ --------------- 238.0/390.3 MB 4.3 MB/s eta 0:00:36\n",
      "   ------------------------ --------------- 239.3/390.3 MB 4.3 MB/s eta 0:00:35\n",
      "   ------------------------ --------------- 240.6/390.3 MB 4.4 MB/s eta 0:00:35\n",
      "   ------------------------ --------------- 241.4/390.3 MB 4.4 MB/s eta 0:00:34\n",
      "   ------------------------ --------------- 242.5/390.3 MB 4.4 MB/s eta 0:00:34\n",
      "   ------------------------ --------------- 243.5/390.3 MB 4.4 MB/s eta 0:00:34\n",
      "   ------------------------- -------------- 244.6/390.3 MB 4.5 MB/s eta 0:00:33\n",
      "   ------------------------- -------------- 245.9/390.3 MB 4.5 MB/s eta 0:00:33\n",
      "   ------------------------- -------------- 247.5/390.3 MB 4.5 MB/s eta 0:00:32\n",
      "   ------------------------- -------------- 249.0/390.3 MB 4.6 MB/s eta 0:00:31\n",
      "   ------------------------- -------------- 251.1/390.3 MB 4.6 MB/s eta 0:00:31\n",
      "   ------------------------- -------------- 253.2/390.3 MB 4.7 MB/s eta 0:00:30\n",
      "   -------------------------- ------------- 255.9/390.3 MB 4.7 MB/s eta 0:00:29\n",
      "   -------------------------- ------------- 257.9/390.3 MB 4.8 MB/s eta 0:00:28\n",
      "   -------------------------- ------------- 260.6/390.3 MB 4.9 MB/s eta 0:00:27\n",
      "   -------------------------- ------------- 262.4/390.3 MB 4.9 MB/s eta 0:00:27\n",
      "   -------------------------- ------------- 263.2/390.3 MB 4.9 MB/s eta 0:00:26\n",
      "   -------------------------- ------------- 263.2/390.3 MB 4.9 MB/s eta 0:00:26\n",
      "   --------------------------- ------------ 263.5/390.3 MB 4.9 MB/s eta 0:00:26\n",
      "   --------------------------- ------------ 263.5/390.3 MB 4.9 MB/s eta 0:00:26\n",
      "   --------------------------- ------------ 263.5/390.3 MB 4.9 MB/s eta 0:00:26\n",
      "   --------------------------- ------------ 263.7/390.3 MB 4.9 MB/s eta 0:00:26\n",
      "   --------------------------- ------------ 264.0/390.3 MB 4.9 MB/s eta 0:00:26\n",
      "   --------------------------- ------------ 264.8/390.3 MB 4.9 MB/s eta 0:00:26\n",
      "   --------------------------- ------------ 265.8/390.3 MB 4.9 MB/s eta 0:00:26\n",
      "   --------------------------- ------------ 267.4/390.3 MB 5.0 MB/s eta 0:00:25\n",
      "   --------------------------- ------------ 269.0/390.3 MB 5.0 MB/s eta 0:00:25\n",
      "   --------------------------- ------------ 270.0/390.3 MB 5.0 MB/s eta 0:00:24\n",
      "   --------------------------- ------------ 271.1/390.3 MB 5.1 MB/s eta 0:00:24\n",
      "   --------------------------- ------------ 272.1/390.3 MB 5.3 MB/s eta 0:00:23\n",
      "   --------------------------- ------------ 272.6/390.3 MB 5.3 MB/s eta 0:00:23\n",
      "   ---------------------------- ----------- 273.4/390.3 MB 5.3 MB/s eta 0:00:23\n",
      "   ---------------------------- ----------- 274.2/390.3 MB 5.3 MB/s eta 0:00:23\n",
      "   ---------------------------- ----------- 275.5/390.3 MB 5.3 MB/s eta 0:00:22\n",
      "   ---------------------------- ----------- 277.1/390.3 MB 5.3 MB/s eta 0:00:22\n",
      "   ---------------------------- ----------- 278.7/390.3 MB 5.3 MB/s eta 0:00:22\n",
      "   ---------------------------- ----------- 280.5/390.3 MB 5.4 MB/s eta 0:00:21\n",
      "   ---------------------------- ----------- 282.9/390.3 MB 5.4 MB/s eta 0:00:20\n",
      "   ----------------------------- ---------- 285.2/390.3 MB 5.5 MB/s eta 0:00:20\n",
      "   ----------------------------- ---------- 287.0/390.3 MB 5.5 MB/s eta 0:00:19\n",
      "   ----------------------------- ---------- 289.4/390.3 MB 5.6 MB/s eta 0:00:18\n",
      "   ----------------------------- ---------- 292.0/390.3 MB 5.7 MB/s eta 0:00:18\n",
      "   ------------------------------ --------- 294.6/390.3 MB 5.8 MB/s eta 0:00:17\n",
      "   ------------------------------ --------- 296.7/390.3 MB 5.8 MB/s eta 0:00:17\n",
      "   ------------------------------ --------- 297.5/390.3 MB 5.9 MB/s eta 0:00:16\n",
      "   ------------------------------ --------- 298.1/390.3 MB 5.9 MB/s eta 0:00:16\n",
      "   ------------------------------ --------- 298.1/390.3 MB 5.9 MB/s eta 0:00:16\n",
      "   ------------------------------ --------- 298.1/390.3 MB 5.9 MB/s eta 0:00:16\n",
      "   ------------------------------ --------- 298.3/390.3 MB 5.8 MB/s eta 0:00:16\n",
      "   ------------------------------ --------- 298.3/390.3 MB 5.8 MB/s eta 0:00:16\n",
      "   ------------------------------ --------- 298.6/390.3 MB 5.8 MB/s eta 0:00:16\n",
      "   ------------------------------ --------- 299.1/390.3 MB 5.8 MB/s eta 0:00:16\n",
      "   ------------------------------ --------- 299.9/390.3 MB 5.9 MB/s eta 0:00:16\n",
      "   ------------------------------ --------- 300.9/390.3 MB 5.9 MB/s eta 0:00:16\n",
      "   ------------------------------ --------- 302.3/390.3 MB 5.9 MB/s eta 0:00:15\n",
      "   ------------------------------- -------- 303.8/390.3 MB 6.0 MB/s eta 0:00:15\n",
      "   ------------------------------- -------- 305.9/390.3 MB 6.0 MB/s eta 0:00:14\n",
      "   ------------------------------- -------- 308.0/390.3 MB 6.2 MB/s eta 0:00:14\n",
      "   ------------------------------- -------- 310.4/390.3 MB 6.2 MB/s eta 0:00:13\n",
      "   -------------------------------- ------- 312.5/390.3 MB 6.3 MB/s eta 0:00:13\n",
      "   -------------------------------- ------- 315.1/390.3 MB 6.5 MB/s eta 0:00:12\n",
      "   -------------------------------- ------- 317.5/390.3 MB 6.6 MB/s eta 0:00:12\n",
      "   -------------------------------- ------- 320.3/390.3 MB 6.6 MB/s eta 0:00:11\n",
      "   --------------------------------- ------ 322.4/390.3 MB 6.6 MB/s eta 0:00:11\n",
      "   --------------------------------- ------ 325.1/390.3 MB 6.7 MB/s eta 0:00:10\n",
      "   --------------------------------- ------ 327.4/390.3 MB 6.7 MB/s eta 0:00:10\n",
      "   --------------------------------- ------ 330.0/390.3 MB 6.8 MB/s eta 0:00:09\n",
      "   ---------------------------------- ----- 332.4/390.3 MB 6.8 MB/s eta 0:00:09\n",
      "   ---------------------------------- ----- 334.8/390.3 MB 6.9 MB/s eta 0:00:09\n",
      "   ---------------------------------- ----- 337.4/390.3 MB 7.0 MB/s eta 0:00:08\n",
      "   ---------------------------------- ----- 340.0/390.3 MB 7.0 MB/s eta 0:00:08\n",
      "   ----------------------------------- ---- 342.4/390.3 MB 7.0 MB/s eta 0:00:07\n",
      "   ----------------------------------- ---- 344.7/390.3 MB 7.1 MB/s eta 0:00:07\n",
      "   ----------------------------------- ---- 347.3/390.3 MB 7.1 MB/s eta 0:00:07\n",
      "   ----------------------------------- ---- 349.4/390.3 MB 7.2 MB/s eta 0:00:06\n",
      "   ----------------------------------- ---- 350.0/390.3 MB 7.2 MB/s eta 0:00:06\n",
      "   ----------------------------------- ---- 350.2/390.3 MB 7.2 MB/s eta 0:00:06\n",
      "   ----------------------------------- ---- 350.2/390.3 MB 7.2 MB/s eta 0:00:06\n",
      "   ----------------------------------- ---- 350.2/390.3 MB 7.2 MB/s eta 0:00:06\n",
      "   ----------------------------------- ---- 350.5/390.3 MB 7.0 MB/s eta 0:00:06\n",
      "   ----------------------------------- ---- 351.0/390.3 MB 6.9 MB/s eta 0:00:06\n",
      "   ------------------------------------ --- 351.8/390.3 MB 6.9 MB/s eta 0:00:06\n",
      "   ------------------------------------ --- 353.1/390.3 MB 6.8 MB/s eta 0:00:06\n",
      "   ------------------------------------ --- 354.4/390.3 MB 6.8 MB/s eta 0:00:06\n",
      "   ------------------------------------ --- 356.3/390.3 MB 6.8 MB/s eta 0:00:06\n",
      "   ------------------------------------ --- 358.4/390.3 MB 6.8 MB/s eta 0:00:05\n",
      "   ------------------------------------ --- 360.4/390.3 MB 6.8 MB/s eta 0:00:05\n",
      "   ------------------------------------- -- 362.8/390.3 MB 6.9 MB/s eta 0:00:05\n",
      "   ------------------------------------- -- 364.9/390.3 MB 6.9 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 367.5/390.3 MB 6.9 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 370.1/390.3 MB 7.0 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 372.8/390.3 MB 7.0 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 375.1/390.3 MB 7.0 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 377.5/390.3 MB 7.0 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 378.8/390.3 MB 7.0 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 379.8/390.3 MB 6.9 MB/s eta 0:00:02\n",
      "   ---------------------------------------  382.5/390.3 MB 6.9 MB/s eta 0:00:02\n",
      "   ---------------------------------------  384.8/390.3 MB 7.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  387.2/390.3 MB 7.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  389.5/390.3 MB 7.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  390.1/390.3 MB 7.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  390.1/390.3 MB 7.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  390.1/390.3 MB 7.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  390.1/390.3 MB 7.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  390.1/390.3 MB 7.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  390.1/390.3 MB 7.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  390.1/390.3 MB 7.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  390.1/390.3 MB 7.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  390.1/390.3 MB 7.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  390.1/390.3 MB 7.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  390.1/390.3 MB 7.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  390.1/390.3 MB 7.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  390.1/390.3 MB 7.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  390.1/390.3 MB 7.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  390.1/390.3 MB 7.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  390.1/390.3 MB 7.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  390.1/390.3 MB 7.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  390.1/390.3 MB 7.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  390.1/390.3 MB 7.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  390.1/390.3 MB 7.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  390.1/390.3 MB 7.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  390.1/390.3 MB 7.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  390.1/390.3 MB 7.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  390.1/390.3 MB 7.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  390.1/390.3 MB 7.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  390.1/390.3 MB 7.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  390.1/390.3 MB 7.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  390.1/390.3 MB 7.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  390.1/390.3 MB 7.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  390.1/390.3 MB 7.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  390.1/390.3 MB 7.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  390.1/390.3 MB 7.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  390.1/390.3 MB 7.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  390.1/390.3 MB 7.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  390.1/390.3 MB 7.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  390.1/390.3 MB 7.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  390.1/390.3 MB 7.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  390.1/390.3 MB 7.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  390.1/390.3 MB 7.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  390.1/390.3 MB 7.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  390.1/390.3 MB 7.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  390.1/390.3 MB 7.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 390.3/390.3 MB 5.1 MB/s eta 0:00:00\n",
      "Downloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading flatbuffers-24.12.23-py2.py3-none-any.whl (30 kB)\n",
      "Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading grpcio-1.68.1-cp312-cp312-win_amd64.whl (4.4 MB)\n",
      "   ---------------------------------------- 0.0/4.4 MB ? eta -:--:--\n",
      "   ----------------------- ---------------- 2.6/4.4 MB 12.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.4/4.4 MB 10.6 MB/s eta 0:00:00\n",
      "Downloading keras-3.7.0-py3-none-any.whl (1.2 MB)\n",
      "   ---------------------------------------- 0.0/1.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.2/1.2 MB 7.7 MB/s eta 0:00:00\n",
      "Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
      "   ---------------------------------------- 0.0/26.4 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 2.4/26.4 MB 12.3 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 4.7/26.4 MB 11.9 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 7.3/26.4 MB 11.9 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 9.7/26.4 MB 12.1 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 12.3/26.4 MB 11.9 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 14.7/26.4 MB 12.0 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 17.3/26.4 MB 12.0 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 19.9/26.4 MB 12.1 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 22.3/26.4 MB 12.0 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 24.6/26.4 MB 12.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.2/26.4 MB 12.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.2/26.4 MB 12.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.2/26.4 MB 12.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.2/26.4 MB 12.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 26.4/26.4 MB 8.6 MB/s eta 0:00:00\n",
      "Downloading ml_dtypes-0.4.1-cp312-cp312-win_amd64.whl (127 kB)\n",
      "Downloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Downloading tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n",
      "   ---------------------------------------- 0.0/5.5 MB ? eta -:--:--\n",
      "   ------------------- -------------------- 2.6/5.5 MB 12.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 5.0/5.5 MB 12.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 5.2/5.5 MB 12.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.5/5.5 MB 8.0 MB/s eta 0:00:00\n",
      "Downloading termcolor-2.5.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Downloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Downloading optree-0.13.1-cp312-cp312-win_amd64.whl (292 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, termcolor, tensorboard-data-server, optree, opt-einsum, ml-dtypes, grpcio, google-pasta, gast, astunparse, absl-py, tensorboard, keras, tensorflow-intel, tensorflow\n",
      "Successfully installed absl-py-2.1.0 astunparse-1.6.3 flatbuffers-24.12.23 gast-0.6.0 google-pasta-0.2.0 grpcio-1.68.1 keras-3.7.0 libclang-18.1.1 ml-dtypes-0.4.1 namex-0.0.8 opt-einsum-3.4.0 optree-0.13.1 tensorboard-2.18.0 tensorboard-data-server-0.7.2 tensorflow-2.18.0 tensorflow-intel-2.18.0 termcolor-2.5.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "!pip install tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5abb5e1-ebfc-41ce-8911-4393d7b65161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Generate Synthetic Data (House Prices)\n",
    "# Square footage (feature) and house prices (target)\n",
    "np.random.seed(42)\n",
    "square_footage = np.random.rand(100) * 1000  # Random square footage between 0 and 1000\n",
    "prices = 100 * square_footage + np.random.randn(100) * 10000  # Price with some noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1438d22e-0cc6-446d-803a-ef6184e91415",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data for better training performance\n",
    "square_footage = square_footage / 1000\n",
    "prices = prices / 100000  # Scale prices for simplicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "055653ec-cff1-44c3-b4cb-a7fe016877ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Split data into training and testing sets\n",
    "train_size = int(0.8 * len(square_footage))\n",
    "x_train, x_test = square_footage[:train_size], square_footage[train_size:]\n",
    "y_train, y_test = prices[:train_size], prices[train_size:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d50bb212-c8dd-4307-a242-26fc8c91c9c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shahroz\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Build the Feedforward Neural Network\n",
    "model = Sequential([\n",
    "    Dense(10, input_dim=1, activation='relu'),  # Hidden layer with 10 neurons\n",
    "    Dense(1)  # Output layer with 1 neuron (for regression output)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e8ae1dc-645e-4ff4-aed8-e50aa4d82b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2154 - mae: 0.3883\n",
      "Epoch 2/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1511 - mae: 0.3216 \n",
      "Epoch 3/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1555 - mae: 0.3319 \n",
      "Epoch 4/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1319 - mae: 0.2927 \n",
      "Epoch 5/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1034 - mae: 0.2585  \n",
      "Epoch 6/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0831 - mae: 0.2247 \n",
      "Epoch 7/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0537 - mae: 0.1712 \n",
      "Epoch 8/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0490 - mae: 0.1714 \n",
      "Epoch 9/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0451 - mae: 0.1687 \n",
      "Epoch 10/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0309 - mae: 0.1359 \n",
      "Epoch 11/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0297 - mae: 0.1444 \n",
      "Epoch 12/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0279 - mae: 0.1442 \n",
      "Epoch 13/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0243 - mae: 0.1321 \n",
      "Epoch 14/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0238 - mae: 0.1340 \n",
      "Epoch 15/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0228 - mae: 0.1355 \n",
      "Epoch 16/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0209 - mae: 0.1270 \n",
      "Epoch 17/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0189 - mae: 0.1179 \n",
      "Epoch 18/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0204 - mae: 0.1218 \n",
      "Epoch 19/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0243 - mae: 0.1355 \n",
      "Epoch 20/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0186 - mae: 0.1178 \n",
      "Epoch 21/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0226 - mae: 0.1274 \n",
      "Epoch 22/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0188 - mae: 0.1188 \n",
      "Epoch 23/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0172 - mae: 0.1150 \n",
      "Epoch 24/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0151 - mae: 0.1033 \n",
      "Epoch 25/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0150 - mae: 0.1025 \n",
      "Epoch 26/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0151 - mae: 0.1056 \n",
      "Epoch 27/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0146 - mae: 0.1014 \n",
      "Epoch 28/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0190 - mae: 0.1199 \n",
      "Epoch 29/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0130 - mae: 0.0940 \n",
      "Epoch 30/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0137 - mae: 0.0982  \n",
      "Epoch 31/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0144 - mae: 0.1007 \n",
      "Epoch 32/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0159 - mae: 0.1065 \n",
      "Epoch 33/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0135 - mae: 0.0988 \n",
      "Epoch 34/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0126 - mae: 0.0926 \n",
      "Epoch 35/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0146 - mae: 0.1020 \n",
      "Epoch 36/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0140 - mae: 0.0986 \n",
      "Epoch 37/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0125 - mae: 0.0938 \n",
      "Epoch 38/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0127 - mae: 0.0934 \n",
      "Epoch 39/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0119 - mae: 0.0927 \n",
      "Epoch 40/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0112 - mae: 0.0885 \n",
      "Epoch 41/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0113 - mae: 0.0848 \n",
      "Epoch 42/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0095 - mae: 0.0802 \n",
      "Epoch 43/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0124 - mae: 0.0947 \n",
      "Epoch 44/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0114 - mae: 0.0886 \n",
      "Epoch 45/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0114 - mae: 0.0893 \n",
      "Epoch 46/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0106 - mae: 0.0856 \n",
      "Epoch 47/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0105 - mae: 0.0832 \n",
      "Epoch 48/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0109 - mae: 0.0853 \n",
      "Epoch 49/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0108 - mae: 0.0823 \n",
      "Epoch 50/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0096 - mae: 0.0796 \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step - loss: 0.0126 - mae: 0.0823\n",
      "Test Loss: 0.0126, Test MAE: 0.0823\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compile the model with Mean Squared Error loss and Adam optimizer\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "# Step 3: Train the Model\n",
    "model.fit(x_train, y_train, epochs=50, batch_size=10, verbose=1)\n",
    "\n",
    "# Step 4: Evaluate the Model\n",
    "loss, mae = model.evaluate(x_test, y_test, verbose=1)\n",
    "print(f\"Test Loss: {loss:.4f}, Test MAE: {mae:.4f}\")\n",
    "\n",
    "# Step 5: Make Predictions\n",
    "predicted_prices = model.predict(x_test)\n",
    "\n",
    "# Visualize the Results\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(x_test, y_test, color='blue', label='Actual Prices')\n",
    "plt.scatter(x_test, predicted_prices, color='red', label='Predicted Prices')\n",
    "plt.xlabel('Square Footage (normalized)')\n",
    "plt.ylabel('House Prices (normalized)')\n",
    "plt.legend()\n",
    "plt.title('Regression with Feedforward Neural Network')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aec4c118-6044-4adb-a228-4cdaf6c462e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shahroz\\AppData\\Local\\Temp\\ipykernel_12296\\1514818020.py:11: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: 1 if x == 'Yes' else (0 if x == 'No' else x))\n",
      "C:\\Users\\Shahroz\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - loss: 1.8821\n",
      "Epoch 2/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 1.4834\n",
      "Epoch 3/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 1.1545\n",
      "Epoch 4/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.8963\n",
      "Epoch 5/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.7059\n",
      "Epoch 6/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.5463\n",
      "Epoch 7/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step - loss: 0.4399\n",
      "Epoch 8/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 325ms/step - loss: 0.3580\n",
      "Epoch 9/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 0.2997\n",
      "Epoch 10/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - loss: 0.2705\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.6776\n",
      "\n",
      "Actual vs Predicted values:\n",
      "Actual: 1, Predicted: 0.28511232137680054\n",
      "Actual: 1, Predicted: 0.08128122985363007\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('Student_Mental_Health.csv')\n",
    "df = df.applymap(lambda x: 1 if x == 'Yes' else (0 if x == 'No' else x))\n",
    "\n",
    "\n",
    "# Encode categorical columns\n",
    "label_encoders = {}\n",
    "categorical_columns = ['Gender', 'FacultyDepartment', 'BloodType', 'DisabilityCertificate', 'Vaccination']\n",
    "for col in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Convert 'Yes'/'No' columns to 1/0\n",
    "\n",
    "# Now scale only numerical columns\n",
    "numerical_columns = ['Age', 'YearsOfUniversity', 'SleepingHours', 'Exercise', 'Drinking', 'Smoking']\n",
    "scaler = StandardScaler()\n",
    "df[numerical_columns] = scaler.fit_transform(df[numerical_columns])\n",
    "\n",
    "# Split data into features (X) and target (y)\n",
    "X = df.drop(columns=['NeedsConsultation'])\n",
    "y = df['NeedsConsultation']  # If this is binary, consider replacing it with a continuous variable for regression\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build Feed Forward Neural Network Model for Regression\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(1))  # No activation function in the output layer for regression\n",
    "\n",
    "# Compile the model with mean squared error loss for regression\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate and print Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f'Mean Squared Error: {mse:.4f}')\n",
    "\n",
    "# Print actual vs predicted values\n",
    "print(\"\\nActual vs Predicted values:\")\n",
    "for i in range(len(y_test)):\n",
    "    print(f\"Actual: {y_test.iloc[i]}, Predicted: {y_pred[i][0]}\")\n",
    "\n",
    "# Save the model\n",
    "model.save('mental_health_regression_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "873f9760-d135-4868-bedc-a2acbc6d2b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shahroz\\AppData\\Local\\Temp\\ipykernel_12296\\2157210304.py:25: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: 1 if x == 'Yes' else (0 if x == 'No' else x))\n",
      "C:\\Users\\Shahroz\\AppData\\Local\\Temp\\ipykernel_12296\\2157210304.py:45: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  X_encrypted = X.applymap(he.encrypt)  # Encrypt all features\n",
      "C:\\Users\\Shahroz\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - loss: 2571587.5000\n",
      "Epoch 2/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - loss: 1921471.2500\n",
      "Epoch 3/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 1318091.3750\n",
      "Epoch 4/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - loss: 822751.4375\n",
      "Epoch 5/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 536895.8125\n",
      "Epoch 6/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 338768.4375\n",
      "Epoch 7/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 186048.5938\n",
      "Epoch 8/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 81052.6641\n",
      "Epoch 9/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - loss: 20364.2812\n",
      "Epoch 10/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step - loss: 446.9062\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000024E03755580> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000024E03755580> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 8039.6342\n",
      "\n",
      "Actual vs Predicted values (decrypted):\n",
      "Actual: 1, Predicted: [90.270386]\n",
      "Actual: 1, Predicted: [91.05591]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Placeholder for homomorphic encryption\n",
    "# In practice, you would replace this with an actual HE library\n",
    "class HomomorphicEncryption:\n",
    "    def encrypt(self, data):\n",
    "        # Placeholder encryption: just a dummy transformation\n",
    "        return data + 1000  # Simulate encryption by adding a large number\n",
    "    \n",
    "    def decrypt(self, encrypted_data):\n",
    "        # Placeholder decryption: reverse the dummy encryption\n",
    "        return encrypted_data - 1000  # Reverse the dummy transformation\n",
    "\n",
    "# Initialize the HE object\n",
    "he = HomomorphicEncryption()\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('Student_Mental_Health.csv')\n",
    "df = df.applymap(lambda x: 1 if x == 'Yes' else (0 if x == 'No' else x))\n",
    "\n",
    "# Encode categorical columns\n",
    "label_encoders = {}\n",
    "categorical_columns = ['Gender', 'FacultyDepartment', 'BloodType', 'DisabilityCertificate', 'Vaccination']\n",
    "for col in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Now scale only numerical columns\n",
    "numerical_columns = ['Age', 'YearsOfUniversity', 'SleepingHours', 'Exercise', 'Drinking', 'Smoking']\n",
    "scaler = StandardScaler()\n",
    "df[numerical_columns] = scaler.fit_transform(df[numerical_columns])\n",
    "\n",
    "# Split data into features (X) and target (y)\n",
    "X = df.drop(columns=['NeedsConsultation'])\n",
    "y = df['NeedsConsultation']  # If this is binary, consider replacing it with a continuous variable for regression\n",
    "\n",
    "# Encrypt the features and target\n",
    "X_encrypted = X.applymap(he.encrypt)  # Encrypt all features\n",
    "y_encrypted = y.apply(he.encrypt)  # Encrypt the target\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encrypted, y_encrypted, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build Feed Forward Neural Network Model for Regression\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(1))  # No activation function in the output layer for regression\n",
    "\n",
    "# Compile the model with mean squared error loss for regression\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32)\n",
    "\n",
    "# Perform predictions on the encrypted test set\n",
    "y_pred_encrypted = model.predict(X_test)\n",
    "\n",
    "# Decrypt the predictions and true values\n",
    "y_pred_decrypted = [he.decrypt(pred) for pred in y_pred_encrypted]\n",
    "y_test_decrypted = [he.decrypt(true) for true in y_test]\n",
    "\n",
    "# Calculate and print Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test_decrypted, y_pred_decrypted)\n",
    "print(f'Mean Squared Error: {mse:.4f}')\n",
    "\n",
    "# Print actual vs predicted values (after decryption)\n",
    "print(\"\\nActual vs Predicted values (decrypted):\")\n",
    "for actual, predicted in zip(y_test_decrypted, y_pred_decrypted):\n",
    "    print(f\"Actual: {actual}, Predicted: {predicted}\")\n",
    "\n",
    "# Save the model (without encryption)\n",
    "model.save('mental_health_regression_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240854fa-bf18-4496-8271-47ce34672714",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
